{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "editable": true,
    "id": "bFY68wFxP5zJ",
    "outputId": "3c657ba8-378a-4cc2-a43f-5b2b1a6981cc",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, balanced_accuracy_score, average_precision_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, brier_score_loss, roc_auc_score\n",
    ")\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qtLNlByZQAEL",
    "outputId": "026b044c-47b5-4bc0-a8cb-d004af435a51"
   },
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df=pd.read_csv(\"Indian Liver Patient Dataset (ILPD).csv\")\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "#Categorical variable\n",
    "df_cleaned['Gender'] = df_cleaned['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "#Binary output\n",
    "df_cleaned['Sickness'] = df_cleaned['Sickness'].replace(2, 0)\n",
    "\n",
    "#NAN values\n",
    "df_cleaned['A/G'] = df_cleaned['A/G'].fillna(df_cleaned['A/G'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Gender   TB   DB  Alkphos  Sgpt  Sgot   TP  ALB   A/G  Sickness\n",
      "3     18       0  1.8  0.7      178    35    36  6.8  3.6  1.10         1\n",
      "31    17       0  0.9  0.2      224    36    45  6.9  4.2  1.55         1\n",
      "35    24       0  1.0  0.2      189    52    31  8.0  4.8  1.50         1\n",
      "89    60       0  2.2  1.0      271    45    52  6.1  2.9  0.90         0\n",
      "104   60       0  0.8  0.2      215    24    17  6.3  3.0  0.90         0\n",
      "106   38       1  2.6  1.2      410    59    57  5.6  3.0  0.80         0\n",
      "114   35       0  2.0  1.1      226    33   135  6.0  2.7  0.80         0\n",
      "115   11       0  0.7  0.1      592    26    29  7.1  4.2  1.40         0\n",
      "116   65       0  0.7  0.2      265    30    28  5.2  1.8  0.52         0\n",
      "124   36       0  5.3  2.3      145    32    92  5.1  2.6  1.00         0\n",
      "130   48       0  0.7  0.2      208    15    30  4.6  2.1  0.80         0\n",
      "132   65       0  1.4  0.6      260    28    24  5.2  2.2  0.70         0\n",
      "135   62       0  0.6  0.1      160    42   110  4.9  2.6  1.10         0\n",
      "139   36       0  5.3  2.3      145    32    92  5.1  2.6  1.00         0\n",
      "143   65       0  0.8  0.2      201    18    22  5.4  2.9  1.10         0\n",
      "150   17       1  0.7  0.2      145    18    36  7.2  3.9  1.18         0\n",
      "151   62       0  0.7  0.2      162    12    17  8.2  3.2  0.60         0\n",
      "157   65       0  1.9  0.8      170    36    43  3.8  1.4  0.58         0\n",
      "161   23       1  2.3  0.8      509    28    44  6.9  2.9  0.70         0\n",
      "X_train: (432, 10), y_train: (432,)\n",
      "X_test: (146, 10), y_test: (146,)\n",
      "Sickness\n",
      "1    307\n",
      "0    125\n",
      "Name: count, dtype: int64\n",
      "Sickness\n",
      "1    80\n",
      "0    66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter positive and negative cases\n",
    "pos = df_cleaned[df_cleaned['Sickness'] == 1]\n",
    "neg = df_cleaned[df_cleaned['Sickness'] == 0]\n",
    "\n",
    "# Determine number of test samples\n",
    "n_test = min(len(pos), len(neg)) // 2\n",
    "\n",
    "# Sample test data\n",
    "test_pos = pos.sample(n=n_test, random_state=42)\n",
    "test_neg = neg.sample(n=n_test, random_state=42)\n",
    "\n",
    "# Combine into balanced test set\n",
    "test = pd.concat([test_pos, test_neg]).reset_index(drop=True)\n",
    "\n",
    "# Indices to remove\n",
    "drop_idx = [3, 31, 35, 89, 104, 106, 114, 115, 116, 124, 130, 132, 135, 139, 143, 150, 151, 157, 161]\n",
    "print(test.loc[drop_idx])\n",
    "test = test.drop(drop_idx, errors='ignore').reset_index(drop=True)\n",
    "\n",
    "# Remaining data for training\n",
    "train = df_cleaned.drop(test.index).reset_index(drop=True)\n",
    "\n",
    "# Remove duplicates\n",
    "test = test.drop_duplicates().reset_index(drop=True)\n",
    "train = train.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X_train, y_train = train.drop(columns=['Sickness']), train['Sickness']\n",
    "X_test, y_test = test.drop(columns=['Sickness']), test['Sickness']\n",
    "\n",
    "# Print sizes and class distributions\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "zEn_74I9Qwck"
   },
   "outputs": [],
   "source": [
    "#Quantum layer\n",
    "n_qubits = 2\n",
    "n_layers = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits, seed=42)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    # Encode inputs into qubits\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    # Trainable quantum layers\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    # Return expectation values\n",
    "    return [qml.expval(qml.PauliZ(w)) for w in range(n_qubits)]\n",
    "\n",
    "# Parameter shapes\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "f_D5UL8CgyZp"
   },
   "outputs": [],
   "source": [
    "#Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=10,          # Stop if no improvement after 10 epochs\n",
    "    restore_best_weights=True  # Restore best weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute original class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Smoothing factor\n",
    "alpha = 0.7\n",
    "\n",
    "# Apply formula to smooth the weights\n",
    "class_weight_dict = {i: 1 + alpha * (weight - 1) for i, weight in enumerate(class_weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 112ms/step - loss: 0.3350 - accuracy: 0.5942 - val_loss: 0.3059 - val_accuracy: 0.7356\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3201 - accuracy: 0.6348 - val_loss: 0.3036 - val_accuracy: 0.7011\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.3106 - accuracy: 0.6551 - val_loss: 0.3069 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3064 - accuracy: 0.6522 - val_loss: 0.3074 - val_accuracy: 0.6552\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2997 - accuracy: 0.6986 - val_loss: 0.2999 - val_accuracy: 0.6437\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.2967 - accuracy: 0.6870 - val_loss: 0.2955 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2983 - accuracy: 0.6928 - val_loss: 0.2923 - val_accuracy: 0.6782\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2915 - accuracy: 0.7014 - val_loss: 0.2958 - val_accuracy: 0.6552\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2883 - accuracy: 0.7101 - val_loss: 0.2957 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2794 - accuracy: 0.7130 - val_loss: 0.2933 - val_accuracy: 0.6552\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2792 - accuracy: 0.7246 - val_loss: 0.2925 - val_accuracy: 0.6782\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2810 - accuracy: 0.7217 - val_loss: 0.2995 - val_accuracy: 0.6782\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2814 - accuracy: 0.6928 - val_loss: 0.2973 - val_accuracy: 0.6437\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2781 - accuracy: 0.7188 - val_loss: 0.2943 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2796 - accuracy: 0.7159 - val_loss: 0.2979 - val_accuracy: 0.6782\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.2722 - accuracy: 0.7188 - val_loss: 0.2923 - val_accuracy: 0.6552\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2721 - accuracy: 0.7101 - val_loss: 0.2926 - val_accuracy: 0.6437\n",
      "3/3 [==============================] - 0s 35ms/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 116ms/step - loss: 0.3320 - accuracy: 0.7014 - val_loss: 0.3080 - val_accuracy: 0.7011\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.3111 - accuracy: 0.7014 - val_loss: 0.3112 - val_accuracy: 0.6322\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.3047 - accuracy: 0.6841 - val_loss: 0.3083 - val_accuracy: 0.6437\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2983 - accuracy: 0.6783 - val_loss: 0.3045 - val_accuracy: 0.6207\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2971 - accuracy: 0.6928 - val_loss: 0.2926 - val_accuracy: 0.6322\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2969 - accuracy: 0.6783 - val_loss: 0.2929 - val_accuracy: 0.6322\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.2925 - accuracy: 0.6754 - val_loss: 0.2962 - val_accuracy: 0.6322\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.2988 - accuracy: 0.6725 - val_loss: 0.2878 - val_accuracy: 0.6437\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2915 - accuracy: 0.6957 - val_loss: 0.2836 - val_accuracy: 0.6552\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.2807 - accuracy: 0.7043 - val_loss: 0.2846 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2895 - accuracy: 0.6928 - val_loss: 0.2790 - val_accuracy: 0.6897\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2836 - accuracy: 0.7101 - val_loss: 0.2810 - val_accuracy: 0.6437\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2831 - accuracy: 0.6841 - val_loss: 0.2843 - val_accuracy: 0.6437\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2768 - accuracy: 0.6986 - val_loss: 0.2776 - val_accuracy: 0.6897\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2753 - accuracy: 0.7159 - val_loss: 0.2788 - val_accuracy: 0.6552\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2737 - accuracy: 0.7101 - val_loss: 0.2967 - val_accuracy: 0.6437\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2784 - accuracy: 0.7014 - val_loss: 0.2774 - val_accuracy: 0.6897\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2874 - accuracy: 0.6754 - val_loss: 0.2877 - val_accuracy: 0.6322\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.2775 - accuracy: 0.6870 - val_loss: 0.2752 - val_accuracy: 0.7126\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2735 - accuracy: 0.7217 - val_loss: 0.2716 - val_accuracy: 0.7126\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2767 - accuracy: 0.7275 - val_loss: 0.2747 - val_accuracy: 0.6897\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2709 - accuracy: 0.7217 - val_loss: 0.2765 - val_accuracy: 0.6782\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.2675 - accuracy: 0.7159 - val_loss: 0.2713 - val_accuracy: 0.7011\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2685 - accuracy: 0.7159 - val_loss: 0.2703 - val_accuracy: 0.7241\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2677 - accuracy: 0.7217 - val_loss: 0.2691 - val_accuracy: 0.7011\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2637 - accuracy: 0.7246 - val_loss: 0.2718 - val_accuracy: 0.7126\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2605 - accuracy: 0.7304 - val_loss: 0.2638 - val_accuracy: 0.7241\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.2576 - accuracy: 0.7159 - val_loss: 0.2691 - val_accuracy: 0.7011\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2623 - accuracy: 0.7275 - val_loss: 0.2598 - val_accuracy: 0.7356\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2661 - accuracy: 0.7246 - val_loss: 0.2738 - val_accuracy: 0.6897\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2587 - accuracy: 0.7188 - val_loss: 0.2641 - val_accuracy: 0.7126\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.2598 - accuracy: 0.7246 - val_loss: 0.2562 - val_accuracy: 0.7701\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2553 - accuracy: 0.7275 - val_loss: 0.2717 - val_accuracy: 0.7011\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2645 - accuracy: 0.7043 - val_loss: 0.2535 - val_accuracy: 0.7241\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2519 - accuracy: 0.7623 - val_loss: 0.2684 - val_accuracy: 0.7126\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2465 - accuracy: 0.7449 - val_loss: 0.2610 - val_accuracy: 0.7356\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2544 - accuracy: 0.7217 - val_loss: 0.2632 - val_accuracy: 0.7126\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2491 - accuracy: 0.7478 - val_loss: 0.2522 - val_accuracy: 0.7471\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2471 - accuracy: 0.7681 - val_loss: 0.2604 - val_accuracy: 0.7126\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2498 - accuracy: 0.7565 - val_loss: 0.2595 - val_accuracy: 0.7126\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.2476 - accuracy: 0.7391 - val_loss: 0.2578 - val_accuracy: 0.7126\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2408 - accuracy: 0.7710 - val_loss: 0.2560 - val_accuracy: 0.7241\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2472 - accuracy: 0.7449 - val_loss: 0.2563 - val_accuracy: 0.7241\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2426 - accuracy: 0.7391 - val_loss: 0.2607 - val_accuracy: 0.7356\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.2435 - accuracy: 0.7884 - val_loss: 0.2548 - val_accuracy: 0.7356\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2446 - accuracy: 0.7304 - val_loss: 0.2652 - val_accuracy: 0.6897\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2495 - accuracy: 0.7536 - val_loss: 0.2590 - val_accuracy: 0.7241\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2433 - accuracy: 0.7449 - val_loss: 0.2705 - val_accuracy: 0.7126\n",
      "3/3 [==============================] - 0s 35ms/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 113ms/step - loss: 0.3485 - accuracy: 0.3035 - val_loss: 0.3514 - val_accuracy: 0.3256\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.3431 - accuracy: 0.5058 - val_loss: 0.3419 - val_accuracy: 0.6279\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3396 - accuracy: 0.6243 - val_loss: 0.3401 - val_accuracy: 0.6163\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.3363 - accuracy: 0.6358 - val_loss: 0.3386 - val_accuracy: 0.5930\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.3319 - accuracy: 0.6763 - val_loss: 0.3353 - val_accuracy: 0.6163\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3287 - accuracy: 0.6705 - val_loss: 0.3315 - val_accuracy: 0.6163\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.3242 - accuracy: 0.6965 - val_loss: 0.3297 - val_accuracy: 0.6047\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3213 - accuracy: 0.6763 - val_loss: 0.3274 - val_accuracy: 0.6279\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.3166 - accuracy: 0.6936 - val_loss: 0.3240 - val_accuracy: 0.6163\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.3118 - accuracy: 0.7023 - val_loss: 0.3217 - val_accuracy: 0.6395\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3086 - accuracy: 0.7197 - val_loss: 0.3205 - val_accuracy: 0.6163\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3027 - accuracy: 0.7081 - val_loss: 0.3193 - val_accuracy: 0.6395\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2995 - accuracy: 0.7110 - val_loss: 0.3161 - val_accuracy: 0.6163\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.3004 - accuracy: 0.7023 - val_loss: 0.3187 - val_accuracy: 0.6163\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2901 - accuracy: 0.7370 - val_loss: 0.3137 - val_accuracy: 0.6395\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2917 - accuracy: 0.7370 - val_loss: 0.3147 - val_accuracy: 0.6163\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2838 - accuracy: 0.7428 - val_loss: 0.3133 - val_accuracy: 0.6395\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2861 - accuracy: 0.7225 - val_loss: 0.3133 - val_accuracy: 0.6279\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2823 - accuracy: 0.7197 - val_loss: 0.3134 - val_accuracy: 0.6395\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2790 - accuracy: 0.7283 - val_loss: 0.3139 - val_accuracy: 0.6395\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2755 - accuracy: 0.7514 - val_loss: 0.3105 - val_accuracy: 0.6163\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2746 - accuracy: 0.7341 - val_loss: 0.3131 - val_accuracy: 0.6395\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.2729 - accuracy: 0.7572 - val_loss: 0.3092 - val_accuracy: 0.6512\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2689 - accuracy: 0.7457 - val_loss: 0.3095 - val_accuracy: 0.6395\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2642 - accuracy: 0.7341 - val_loss: 0.3144 - val_accuracy: 0.6279\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2662 - accuracy: 0.7428 - val_loss: 0.3111 - val_accuracy: 0.6395\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2722 - accuracy: 0.7283 - val_loss: 0.3291 - val_accuracy: 0.6047\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2646 - accuracy: 0.7341 - val_loss: 0.3116 - val_accuracy: 0.6163\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2571 - accuracy: 0.7630 - val_loss: 0.3220 - val_accuracy: 0.6163\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2567 - accuracy: 0.7630 - val_loss: 0.3007 - val_accuracy: 0.6395\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2483 - accuracy: 0.7775 - val_loss: 0.3177 - val_accuracy: 0.6047\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.2551 - accuracy: 0.7283 - val_loss: 0.3185 - val_accuracy: 0.6395\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2444 - accuracy: 0.7659 - val_loss: 0.3259 - val_accuracy: 0.6163\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2471 - accuracy: 0.7601 - val_loss: 0.3219 - val_accuracy: 0.6279\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2426 - accuracy: 0.7775 - val_loss: 0.3298 - val_accuracy: 0.6047\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.2398 - accuracy: 0.7399 - val_loss: 0.3366 - val_accuracy: 0.6163\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2413 - accuracy: 0.7486 - val_loss: 0.3326 - val_accuracy: 0.5930\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2398 - accuracy: 0.7659 - val_loss: 0.3232 - val_accuracy: 0.5930\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2348 - accuracy: 0.7919 - val_loss: 0.3332 - val_accuracy: 0.6163\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2434 - accuracy: 0.7688 - val_loss: 0.3334 - val_accuracy: 0.5930\n",
      "3/3 [==============================] - 0s 34ms/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 113ms/step - loss: 0.3519 - accuracy: 0.7081 - val_loss: 0.2946 - val_accuracy: 0.7093\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.3213 - accuracy: 0.6994 - val_loss: 0.2968 - val_accuracy: 0.6628\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3038 - accuracy: 0.7023 - val_loss: 0.3039 - val_accuracy: 0.6512\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2949 - accuracy: 0.6821 - val_loss: 0.3166 - val_accuracy: 0.6512\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2890 - accuracy: 0.6994 - val_loss: 0.2953 - val_accuracy: 0.6395\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.2817 - accuracy: 0.7023 - val_loss: 0.3016 - val_accuracy: 0.6047\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2855 - accuracy: 0.6705 - val_loss: 0.3082 - val_accuracy: 0.6047\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2796 - accuracy: 0.6936 - val_loss: 0.2892 - val_accuracy: 0.6395\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2749 - accuracy: 0.7168 - val_loss: 0.2814 - val_accuracy: 0.6628\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2779 - accuracy: 0.7052 - val_loss: 0.2885 - val_accuracy: 0.6395\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2719 - accuracy: 0.7052 - val_loss: 0.2981 - val_accuracy: 0.6047\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2714 - accuracy: 0.6936 - val_loss: 0.2871 - val_accuracy: 0.6395\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.2650 - accuracy: 0.7023 - val_loss: 0.2755 - val_accuracy: 0.6628\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2765 - accuracy: 0.6994 - val_loss: 0.2817 - val_accuracy: 0.6512\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.2716 - accuracy: 0.6965 - val_loss: 0.2896 - val_accuracy: 0.6279\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2627 - accuracy: 0.7254 - val_loss: 0.2770 - val_accuracy: 0.6744\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.2561 - accuracy: 0.7341 - val_loss: 0.2844 - val_accuracy: 0.6628\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.2619 - accuracy: 0.6936 - val_loss: 0.2815 - val_accuracy: 0.6744\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2576 - accuracy: 0.7139 - val_loss: 0.2803 - val_accuracy: 0.6512\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.2537 - accuracy: 0.7168 - val_loss: 0.2839 - val_accuracy: 0.6395\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.2554 - accuracy: 0.7168 - val_loss: 0.2765 - val_accuracy: 0.6628\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.2510 - accuracy: 0.7486 - val_loss: 0.2801 - val_accuracy: 0.6628\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2506 - accuracy: 0.7283 - val_loss: 0.2848 - val_accuracy: 0.6163\n",
      "3/3 [==============================] - 0s 34ms/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 112ms/step - loss: 0.3824 - accuracy: 0.3699 - val_loss: 0.3750 - val_accuracy: 0.4651\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3449 - accuracy: 0.5376 - val_loss: 0.3466 - val_accuracy: 0.5349\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.3359 - accuracy: 0.5751 - val_loss: 0.3375 - val_accuracy: 0.5814\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3156 - accuracy: 0.6098 - val_loss: 0.3437 - val_accuracy: 0.6047\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3102 - accuracy: 0.6069 - val_loss: 0.3306 - val_accuracy: 0.6163\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3084 - accuracy: 0.6156 - val_loss: 0.3254 - val_accuracy: 0.5814\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3045 - accuracy: 0.6243 - val_loss: 0.3225 - val_accuracy: 0.6163\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3088 - accuracy: 0.6329 - val_loss: 0.3201 - val_accuracy: 0.6047\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2940 - accuracy: 0.6821 - val_loss: 0.3176 - val_accuracy: 0.6163\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2961 - accuracy: 0.6763 - val_loss: 0.3166 - val_accuracy: 0.6047\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2938 - accuracy: 0.6705 - val_loss: 0.3164 - val_accuracy: 0.6279\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.2905 - accuracy: 0.6561 - val_loss: 0.3147 - val_accuracy: 0.6163\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2887 - accuracy: 0.6590 - val_loss: 0.3161 - val_accuracy: 0.6047\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2868 - accuracy: 0.6705 - val_loss: 0.3159 - val_accuracy: 0.6047\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2800 - accuracy: 0.7023 - val_loss: 0.3223 - val_accuracy: 0.5930\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2824 - accuracy: 0.6705 - val_loss: 0.3198 - val_accuracy: 0.6047\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.2698 - accuracy: 0.6994 - val_loss: 0.3160 - val_accuracy: 0.6047\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2778 - accuracy: 0.6994 - val_loss: 0.3121 - val_accuracy: 0.6279\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2698 - accuracy: 0.7023 - val_loss: 0.3137 - val_accuracy: 0.6279\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2711 - accuracy: 0.6763 - val_loss: 0.3134 - val_accuracy: 0.6047\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2647 - accuracy: 0.7139 - val_loss: 0.3062 - val_accuracy: 0.6628\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2739 - accuracy: 0.7168 - val_loss: 0.3040 - val_accuracy: 0.6279\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2618 - accuracy: 0.7023 - val_loss: 0.3141 - val_accuracy: 0.6512\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2633 - accuracy: 0.7081 - val_loss: 0.3093 - val_accuracy: 0.6512\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2539 - accuracy: 0.7283 - val_loss: 0.3023 - val_accuracy: 0.6395\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2535 - accuracy: 0.7341 - val_loss: 0.2991 - val_accuracy: 0.6395\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2567 - accuracy: 0.7197 - val_loss: 0.2987 - val_accuracy: 0.6628\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.2583 - accuracy: 0.7081 - val_loss: 0.2998 - val_accuracy: 0.6512\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2553 - accuracy: 0.7197 - val_loss: 0.3131 - val_accuracy: 0.6047\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2606 - accuracy: 0.7197 - val_loss: 0.3042 - val_accuracy: 0.6163\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2408 - accuracy: 0.7630 - val_loss: 0.3038 - val_accuracy: 0.6395\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.2380 - accuracy: 0.7572 - val_loss: 0.3010 - val_accuracy: 0.6395\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2333 - accuracy: 0.7543 - val_loss: 0.3032 - val_accuracy: 0.6395\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.2409 - accuracy: 0.7543 - val_loss: 0.3114 - val_accuracy: 0.6512\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2392 - accuracy: 0.7514 - val_loss: 0.3072 - val_accuracy: 0.6395\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2486 - accuracy: 0.7254 - val_loss: 0.3060 - val_accuracy: 0.6279\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.2391 - accuracy: 0.7399 - val_loss: 0.3031 - val_accuracy: 0.6744\n",
      "3/3 [==============================] - 0s 34ms/step\n",
      "Accuracy: Mean=0.6781, Std=0.0367\n",
      "Precision: Mean=0.8236, Std=0.0514\n",
      "Recall: Mean=0.7003, Std=0.0176\n",
      "F1-score: Mean=0.7560, Std=0.0231\n",
      "AUC: Mean=0.7442, Std=0.0496\n",
      "Specificity: Mean=0.6240, Std=0.1280\n"
     ]
    }
   ],
   "source": [
    "# Define Stratified K-Fold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "# Focal loss for binary classification\n",
    "loss = losses.BinaryFocalCrossentropy(gamma=1.0, alpha=0.3)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    # Split data\n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_cv = scaler.fit_transform(X_train_cv)\n",
    "    X_val_cv = scaler.transform(X_val_cv)\n",
    "\n",
    "    # Hybrid quantum-classical model\n",
    "    model_cv = Sequential([\n",
    "        InputLayer(input_shape=(X_train_cv.shape[1],)),\n",
    "        Dense(256, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(n_qubits),\n",
    "        qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model_cv.compile(loss=loss, optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train model\n",
    "    history_cv = model_cv.fit(\n",
    "        X_train_cv, y_train_cv,\n",
    "        batch_size=32, epochs=100,\n",
    "        validation_data=(X_val_cv, y_val_cv),\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_val_pred_prob = model_cv.predict(X_val_cv)\n",
    "    y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_val_cv, y_val_pred)\n",
    "    prec = precision_score(y_val_cv, y_val_pred, zero_division=0)\n",
    "    rec = recall_score(y_val_cv, y_val_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val_cv, y_val_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_val_cv, y_val_pred_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_cv, y_val_pred).ravel()\n",
    "    spe = tn / (tn + fp)\n",
    "\n",
    "    cv_scores.append([acc, prec, rec, f1, auc, spe])\n",
    "\n",
    "# Convert to array and compute mean & std\n",
    "cv_scores = np.array(cv_scores)\n",
    "metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\", \"Specificity\"]\n",
    "\n",
    "# Print metrics\n",
    "for i, name in enumerate(metric_names):\n",
    "    print(f\"{name}: Mean={cv_scores[:, i].mean():.4f}, Std={cv_scores[:, i].std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Metrics------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To all training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 116ms/step - loss: 0.3506 - accuracy: 0.6883 - val_loss: 0.3361 - val_accuracy: 0.7685\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3494 - accuracy: 0.6914 - val_loss: 0.3366 - val_accuracy: 0.7685\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3477 - accuracy: 0.7068 - val_loss: 0.3335 - val_accuracy: 0.7778\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3445 - accuracy: 0.6914 - val_loss: 0.3288 - val_accuracy: 0.7685\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.3411 - accuracy: 0.6698 - val_loss: 0.3219 - val_accuracy: 0.7685\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3363 - accuracy: 0.6574 - val_loss: 0.3180 - val_accuracy: 0.7130\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3315 - accuracy: 0.6636 - val_loss: 0.3107 - val_accuracy: 0.7222\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.3286 - accuracy: 0.6574 - val_loss: 0.3037 - val_accuracy: 0.7037\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.3219 - accuracy: 0.6636 - val_loss: 0.3008 - val_accuracy: 0.7130\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3205 - accuracy: 0.6481 - val_loss: 0.2950 - val_accuracy: 0.7222\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3127 - accuracy: 0.6852 - val_loss: 0.2872 - val_accuracy: 0.7315\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.3127 - accuracy: 0.6698 - val_loss: 0.2831 - val_accuracy: 0.7407\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.3097 - accuracy: 0.6759 - val_loss: 0.2802 - val_accuracy: 0.7407\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.3043 - accuracy: 0.6543 - val_loss: 0.2752 - val_accuracy: 0.7685\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.3016 - accuracy: 0.6759 - val_loss: 0.2723 - val_accuracy: 0.7315\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.3039 - accuracy: 0.6914 - val_loss: 0.2600 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.2943 - accuracy: 0.7068 - val_loss: 0.2598 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2896 - accuracy: 0.6975 - val_loss: 0.2630 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2912 - accuracy: 0.6790 - val_loss: 0.2519 - val_accuracy: 0.7407\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2928 - accuracy: 0.7037 - val_loss: 0.2553 - val_accuracy: 0.7407\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2892 - accuracy: 0.7068 - val_loss: 0.2494 - val_accuracy: 0.7870\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.2915 - accuracy: 0.6914 - val_loss: 0.2480 - val_accuracy: 0.7685\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2889 - accuracy: 0.6821 - val_loss: 0.2518 - val_accuracy: 0.7685\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2817 - accuracy: 0.7346 - val_loss: 0.2410 - val_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2839 - accuracy: 0.7284 - val_loss: 0.2383 - val_accuracy: 0.7870\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.2775 - accuracy: 0.7099 - val_loss: 0.2368 - val_accuracy: 0.7963\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2714 - accuracy: 0.7130 - val_loss: 0.2361 - val_accuracy: 0.7870\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2715 - accuracy: 0.7191 - val_loss: 0.2315 - val_accuracy: 0.7870\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2879 - accuracy: 0.6821 - val_loss: 0.2356 - val_accuracy: 0.7685\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.2803 - accuracy: 0.6944 - val_loss: 0.2312 - val_accuracy: 0.7963\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2753 - accuracy: 0.7253 - val_loss: 0.2341 - val_accuracy: 0.7870\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2739 - accuracy: 0.7284 - val_loss: 0.2368 - val_accuracy: 0.7870\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2639 - accuracy: 0.7284 - val_loss: 0.2329 - val_accuracy: 0.7870\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2706 - accuracy: 0.7160 - val_loss: 0.2266 - val_accuracy: 0.7870\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.2717 - accuracy: 0.6914 - val_loss: 0.2339 - val_accuracy: 0.7870\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.2718 - accuracy: 0.7130 - val_loss: 0.2229 - val_accuracy: 0.8056\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2711 - accuracy: 0.7500 - val_loss: 0.2253 - val_accuracy: 0.7963\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.2630 - accuracy: 0.7099 - val_loss: 0.2362 - val_accuracy: 0.7593\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.2634 - accuracy: 0.7006 - val_loss: 0.2310 - val_accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2538 - accuracy: 0.7531 - val_loss: 0.2341 - val_accuracy: 0.7778\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2543 - accuracy: 0.7315 - val_loss: 0.2356 - val_accuracy: 0.7685\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2603 - accuracy: 0.7284 - val_loss: 0.2285 - val_accuracy: 0.7870\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.2491 - accuracy: 0.7531 - val_loss: 0.2277 - val_accuracy: 0.7778\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2520 - accuracy: 0.7500 - val_loss: 0.2202 - val_accuracy: 0.7963\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2562 - accuracy: 0.7500 - val_loss: 0.2205 - val_accuracy: 0.8148\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2499 - accuracy: 0.7531 - val_loss: 0.2228 - val_accuracy: 0.7963\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2630 - accuracy: 0.7160 - val_loss: 0.2342 - val_accuracy: 0.7593\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2552 - accuracy: 0.7099 - val_loss: 0.2223 - val_accuracy: 0.7870\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2520 - accuracy: 0.7253 - val_loss: 0.2215 - val_accuracy: 0.8056\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2485 - accuracy: 0.7531 - val_loss: 0.2286 - val_accuracy: 0.7778\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2478 - accuracy: 0.7593 - val_loss: 0.2300 - val_accuracy: 0.7685\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.2433 - accuracy: 0.7654 - val_loss: 0.2274 - val_accuracy: 0.7963\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.2399 - accuracy: 0.7469 - val_loss: 0.2237 - val_accuracy: 0.8056\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.2521 - accuracy: 0.7438 - val_loss: 0.2288 - val_accuracy: 0.7963\n"
     ]
    }
   ],
   "source": [
    "# Hybrid quantum-classical model\n",
    "model_final = Sequential([\n",
    "    InputLayer(input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(256, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation=\"relu\", kernel_initializer=\"glorot_uniform\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(n_qubits),\n",
    "    qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_final.compile(loss=loss, optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model again with all the train data\n",
    "history_final = model_final.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    batch_size=32, epochs=100,\n",
    "    validation_split = 0.25,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_411 (Dense)           (None, 256)               2816      \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      " keras_layer_89 (KerasLayer  (None, 2)                 8         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35981 (140.55 KB)\n",
      "Trainable params: 35981 (140.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 34ms/step\n",
      "=== Resultados del Modelo ===\n",
      "Accuracy:           0.8425\n",
      "Precision:          0.8065\n",
      "Recall (Sensitivity): 0.9375\n",
      "Specificity:        0.7273\n",
      "F1-score:           0.8671\n",
      "Balanced Accuracy:  0.8324\n",
      "ROC AUC:            0.9148\n",
      "PR AUC:             0.9280\n",
      "MCC:                0.6880\n",
      "Cohen's Kappa:      0.6764\n",
      "Brier Score:        0.1541\n"
     ]
    }
   ],
   "source": [
    "# Predicctions\n",
    "y_pred_prob = model_final.predict(X_test_scaled)  \n",
    "y_pred = (y_pred_prob > 0.45).astype(\"int\")  \n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)  \n",
    "recall = recall_score(y_test, y_pred)   # Sensitivity\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Specificity from confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "pr_auc = average_precision_score(y_test, y_pred_prob)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "brier = brier_score_loss(y_test, y_pred_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Metrics ===\")\n",
    "print(f'Accuracy:           {accuracy:.4f}')\n",
    "print(f'Precision:          {precision:.4f}')\n",
    "print(f'Recall (Sensitivity): {recall:.4f}')\n",
    "print(f'Specificity:        {specificity:.4f}')\n",
    "print(f'F1-score:           {f1:.4f}')\n",
    "print(f'Balanced Accuracy:  {balanced_acc:.4f}')\n",
    "print(f'ROC AUC:            {roc_auc:.4f}')\n",
    "print(f'PR AUC:             {pr_auc:.4f}')\n",
    "print(f'MCC:                {mcc:.4f}')\n",
    "print(f'Cohen\\'s Kappa:      {kappa:.4f}')\n",
    "print(f'Brier Score:        {brier:.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
